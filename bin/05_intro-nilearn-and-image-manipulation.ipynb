{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Nilearn and image manipulation\n",
    "\n",
    "The goal of this notebook is to help get you comfortable with manipulating functional and anatomical images using nilearn. We'll be using the techniques we learned here in our final analysis...\n",
    "\n",
    "#### Content:\n",
    "1. Basic Image Operations and Masking\n",
    "2. Resampling data to work across modalities (T1/FUNC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matplotlib magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab some sample images from fmriprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base directory for fmriprep output\n",
    "fmriprep_dir = '../data/ds000030/derivatives/fmriprep/'\n",
    "layout=bids.BIDSLayout(fmriprep_dir, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display files inside of anatomy folder \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warming up with Nilearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Image operations\n",
    "Here we show how easy it is to apply a mask to nifti images using nilearn. \n",
    "We first pick an example T1 image and mask from the fmriprep output, then we apply the mask and view the result..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_T1 = os.path.join(t1_dir,'sub-10788_T1w_preproc.nii.gz')\n",
    "ex_bm = os.path.join(t1_dir,'sub-10788_T1w_brainmask.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing T1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nilearn uses nibabel under the hood to store nifti images. So you can think of images (similar to nibabel) as a 3D array (volume) with values assigned to each (x,y,z) coordinate. With 3D arrays we can perform operations and nilearn makes simple\n",
    "\n",
    "Say we wanted to invert a T1 image, that is flip the colorscale. We could do this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Inverting a T1 image example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we could use a similar technique to apply a mask. \n",
    "A mask is simply a 3D volume with 0's and 1's. The 1's indicate the areas in which areas are to be preserved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind applying a mask is multiplying the mask directly by the image in an element-wise fashion. \n",
    "The end result is that all voxels (x,y,z) in the T1 image corresponding with a 1 in the mask with the same coordinate (x,y,z) is preserved. Everything else is put to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying a mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** \n",
    "\n",
    "Try applying the mask but getting everything but the brain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Functional Data\n",
    "\n",
    "So far, we've been working with structural data which is 3-dimensional. However the end goal of this course is to analyze functional MRI data so it's about time we introduce it! \n",
    "\n",
    "Functional data consists of full 3D brain volumes that are *sampled* at multiple time points. Therefore you have a sequence of 3D brain volumes, stepping through sequences is stepping through time and therefore time is our 4th dimension! Here's a visualization to make this concept more clear:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../static/images/4D_array.png\" alt=\"Drawing\" align=\"middle\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each index along the 4th dimensions (called TR for \"Repetition Time\", or Sample) is a full 3D scan of the brain. Pulling out volumes from 4-dimensional images is similar to that of 3-dimensional images except you're now dealing with:\n",
    "\n",
    "\n",
    "<code> img.slicer[x,y,z,time] </code>!\n",
    "\n",
    "Let's try a couple of examples to familiarize ourselves with dealing with 4D images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we'll load in our Functional data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, take a look at the shape of the functional image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the Functional MR scan contains *4 dimensions*. This is in the form of $(x,y,z,t)$, where $t$ is time. \n",
    "We can use slicer as usual where instead of using 3 dimensions we use 4. \n",
    "\n",
    "For example:\n",
    "\n",
    "<code> func.slicer[x,y,z] </code> \n",
    "\n",
    "vs.\n",
    "\n",
    "<code> func.slicer[x,y,z,t] </code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Try pulling out the 5th TR and visualizing it using <code>plot.plot_epi</code>. <code>plot_epi</code> is exactly the same as <code>plot_anat</code> except it displays using colors that make more sense for functional images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull the 5th TR\n",
    "func_vol5 = func.??[?,?,?,?]\n",
    "plot.plot_epi(?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resampling\n",
    "Recall from our nibabel exploration of neuroimaging data:\n",
    "\n",
    "- T1 images are typically composed of voxels that are 1x1x1 in dimension\n",
    "- Functional images are typically composed of voxels that are 2x2x2 in dimension\n",
    "\n",
    "If we'd like to overlay our functional on top of our T1 (for visualization purposes, or analyses), then we need to match the size of the voxels! \n",
    "\n",
    "Think of this like trying to overlay a 10x10 JPEG and a 20x20 JPEG on top of each other. To get perfect overlay we need to resize (or more accurately *resample*) our JPEGs to match!\n",
    "\n",
    "**Note**: \n",
    "Resampling is a method of interpolating in between data-points. When we stretch an image we need to figure out what goes in the spaces that are created via stretching - resampling does just that. In fact, resizing any type of image is actually just resampling to new dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's resampling some MRI data using nilearn. \n",
    "\n",
    "**Goal**: Match the dimensions of the structural image to that of the functional image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Files we'll be using (Notice that we're using _space-MNI..._ which means they are normalized brains)\n",
    "ex_mni_T1 = os.path.join(t1_dir,'sub-10788_T1w_space-MNI152NLin2009cAsym_preproc.nii.gz')\n",
    "ex_mni_FUNC = os.path.join(func_dir,'sub-10788_task-rest_bold_space-MNI152NLin2009cAsym_preproc.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note below that when we load an image, it reads in as a nibabel image. \n",
    "Meaning we can use the same utilities we used in nibabel on this data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling in nilearn is as easy as telling it which image you want to sample and what the target image is.\n",
    "Structure of function:\n",
    "\n",
    "<code>img.resample_to_img(source_img,target_img,interpolation)</code>\n",
    "1. <code>source_img</code> - the image you want to sample\n",
    "2. <code>target_img</code> - the image you wish to *resample to* \n",
    "3. <code>interpolation</code> - the method of interpolation\n",
    "\n",
    "A note on **interpolation**\n",
    "\n",
    "nilearn supports 3 types of interpolation, the one you'll use depends on the type of data you're resampling!\n",
    "1. **continuous** - Interpolate but maintain some edge features.  Ideal for structural images where edges are well-defined. Uses $3^\\text{rd}$-order spline interpolation.\n",
    "2. **linear (default)** - Interpolate uses a combination of neighbouring voxels - will blur. Uses trilinear interpolation.\n",
    "3. **nearest** - matches value of closest voxel (majority vote from neighbours). This is ideal for masks which are binary since it will preserve the 0's and 1's and will not produce in-between values (ex: 0.342). Also ideal for numeric labels where values are 0,1,2,3... (parcellations). Uses nearest-neighbours interpolation with majority vote.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try playing around with methods of interpolation\n",
    "#options: 'linear','continuous','nearest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Using **Native** T1 and **T1w** resting state functional do the following:\n",
    "1. Resample the native T1 image to resting state size\n",
    "2. Replace the brain in the T1 image with the first frame of the resting state brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Files we'll need\n",
    "\n",
    "#This is the pre-processed T1 data that hasn't been standardized\n",
    "ex_T1 = os.path.join(t1_dir,'sub-10171_T1w_preproc.nii.gz')\n",
    "\n",
    "#This is the brain mask of the above T1\n",
    "ex_t1_bm = os.path.join(t1_dir,'sub-10171_T1w_brainmask.nii.gz')\n",
    "\n",
    "#This is the pre-processed resting state data that hasn't been standardized\n",
    "ex_func = os.path.join(func_dir,'sub-10171_task-rest_bold_space-T1w_preproc.nii.gz')\n",
    "\n",
    "#This is the associated mask for the resting state image.\n",
    "ex_func_bm = os.path.join(func_dir,'sub-10171_task-rest_bold_space-T1w_brainmask.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The first step we need to do is to make sure the dimensions for our T1 image and resting state image match each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resample the T1 to the size of the functional image!\n",
    "resamp_t1 = img.resample_to_img(source_img=??, target_img=??, interpolation='continuous')\n",
    "plot.plot_anat( ?? )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next we want to make sure that the brain mask for the T1 is also the same dimensions as the functional image. This is exactly the same as above, except we use the brain mask as the source.\n",
    "\n",
    "What kind of interpolation should we use for masks? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resamp_bm = ??\n",
    "#Plot the image!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've resampled both our T1 and our brain mask. We now want to remove the brain from the T1 image so that we can replace it with the funtional image instead. Remember to do this we need to:\n",
    "\n",
    "1. Invert the T1 mask\n",
    "2. Apply the inverted mask to the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_bm_t1 = img.math_img('??',a=??)\n",
    "\n",
    "#Plot the image!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply the mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resamp_t1_nobrain = ??\n",
    "\n",
    "#Plot the image!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a skull missing the structural T1 brain. The final steps is to stick in the brain from the functional image into the now brainless head. First we need to remove the surrounding signal from the functional image.\n",
    "\n",
    "Since a functional image is 4-Dimensional, we'll need to pull the first volume to work with. This is because the structural image is 3-dimensional and operations will fail if we try to mix 3D and 4D data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's visualize the first volume of the functional image:\n",
    "func_img = img.load_img(??)\n",
    "\n",
    "#Pick the first volume (index 0) using \"slicer\"\n",
    "first_vol = ??.slicer[?,?,?,?]\n",
    "\n",
    "#Plot the first volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the figure above, the image has some \"signal\" outside of the brain. In order to place this within the now brainless head we made earlier, we need to mask out the functional MR data as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mask first_vol using ex_func_bm\n",
    "masked_func = ??\n",
    "\n",
    "#Plot the masked functional image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to stick this data into the head of the T1 data. Since the hole in the T1 data is represented as $0$'s. We can add the two images together to place the functional data into the void:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the two images together\n",
    "combined_img = ??\n",
    "\n",
    "#Plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finished!\n",
    "Hopefully you've gained some intuition and comfort in dealing with MRI images using nilearn/nibabel. \n",
    "\n",
    "Now we'll take what we've used here, add some additional features and perform a full analysis on a dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
